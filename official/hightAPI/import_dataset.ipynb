{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPComplete.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建会话环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集结构\n",
    "- 一个__数据集__包含多个__元素__，每个__元素的结构__都相同。一个元素包含一个或多个`tf.Tensor`对象，这些对象被称为__组件__\n",
    "- __嵌套结构__映射到__元素的结构__,元素可以是__单个张量__，__张量元组__，__张量的嵌套元组__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_4x10: Tensor(\"random_uniform_1:0\", shape=(4, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 创建张量\n",
    "tensor_4=tf.random_uniform([4])\n",
    "tensor_4x10 = tf.random_uniform([4,10])\n",
    "tensor_4x100=tf.random_uniform([4,100],maxval=100,dtype=tf.int32)\n",
    "print(\"tensor_4x10:\",tensor_4x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (10,), types: tf.float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 单个张量的数据集\n",
    "dataset1=tf.data.Dataset.from_tensor_slices(tensor_4x10)\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (100,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量元组的数据集\n",
    "dataset2=tf.data.Dataset.from_tensor_slices((tensor_4,tensor_4x100))\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((10,), ((), (100,))), types: (tf.float32, (tf.float32, tf.int32))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 嵌套张量的数据集\n",
    "dataset3=tf.data.Dataset.zip((dataset1,dataset2))\n",
    "dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {a: (), b: (100,)}, types: {a: tf.float32, b: tf.int32}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为元素的每个组件命名通常会带来便利性\n",
    "dataset_name=tf.data.Dataset.from_tensor_slices({'a':tensor_4,'b':tensor_4x100})\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集转换\n",
    "`Dataset` 转换支持任何结构的数据集\n",
    "\n",
    "在使用 Dataset.map()、Dataset.flat_map() 和 Dataset.filter() 转换时（这些转换会对每个元素应用一个函数），元素结构决定了函数的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset1 = dataset1.map(lambda x: ...)\n",
    "\n",
    "# dataset2 = dataset2.flat_map(lambda x, y: ...)\n",
    "\n",
    "# Note: Argument destructuring is not available in Python 3.\n",
    "# dataset3 = dataset3.filter(lambda x, (y, z): ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单次迭代器\n",
    "- 使用`Dataset`对象的`make_one_shot_iterator`方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=0 i=0\n",
      "value=0 i=1\n",
      "value=0 i=2\n",
      "value=0 i=3\n",
      "value=0 i=4\n",
      "value=0 i=5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = tf.data.Dataset.range(100)\n",
    "iterator=dataset.make_one_shot_iterator()\n",
    "next_element=iterator.get_next()\n",
    "# print(next_element)\n",
    "for i in range(6):\n",
    "    value = tf.Session().run(next_element)\n",
    "    print(\"value={}\".format(value),\"i={}\".format(i))\n",
    "#     assert i==value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test(sess,epoch,element):\n",
    "    for i in range(epoch):\n",
    "        value = sess.run(element)\n",
    "#         print(\"value={}\".format(value),\"i={}\".format(i))\n",
    "        print(\"value=%d\"%value,\"i=%d\"%i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可初始化迭代器\n",
    "- 在同一个`Dataset`对象进行初始化\n",
    "- 使用`Dataset`对象的`make_initializable_iterator`方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value=0 i=0\n",
      "value=1 i=1\n",
      "value=2 i=2\n",
      "value=3 i=3\n",
      "value=4 i=4\n",
      "value=5 i=5\n",
      "value=6 i=6\n",
      "value=7 i=7\n",
      "value=8 i=8\n",
      "value=9 i=9\n",
      "value=0 i=0\n",
      "value=1 i=1\n",
      "value=2 i=2\n",
      "value=3 i=3\n",
      "value=4 i=4\n"
     ]
    }
   ],
   "source": [
    "range_num = tf.placeholder(tf.int64)\n",
    "dataset = tf.data.Dataset.range(range_num)\n",
    "itor=dataset.make_initializable_iterator()\n",
    "next_element=itor.get_next()\n",
    "\n",
    "epoch_5=5\n",
    "epoch_10=10\n",
    "\n",
    "sess.run(itor.initializer,feed_dict={range_num:epoch_10})\n",
    "print_test(sess,epoch_10,next_element)\n",
    "\n",
    "sess.run(itor.initializer,feed_dict={range_num:epoch_5})\n",
    "print_test(sess,epoch_5,next_element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可重新初始化迭代器\n",
    "- 用`tf.data.Iterator.from_structure`方法创建迭代器\n",
    "- 通过多个不同的 `Dataset` 对象进行初始化\n",
    "- 这些对象具有相同的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterator(init_op,element,epoch):\n",
    "#     始化迭代器\n",
    "    sess.run(init_op)\n",
    "    for i in range(epoch):\n",
    "        sess.run(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先创建多个Dataset对象\n",
    "t_dataset=tf.data.Dataset.range(epoch_10)\n",
    "v_dadtaset=tf.data.Dataset.range(epoch_5)\n",
    "\n",
    "# 创建迭代器\n",
    "iterator = tf.data.Iterator.from_structure(t_dataset.output_types,t_dataset.output_shapes)\n",
    "\n",
    "# 获取迭代元素\n",
    "next_element=iterator.get_next()\n",
    "\n",
    "# 根据不同的Dataset对象，创建迭代器的初始化操作\n",
    "t_d_init_op=iterator.make_initializer(t_dataset)\n",
    "v_d_init_op=iterator.make_initializer(v_dadtaset)\n",
    "\n",
    "for _ in range(epoch_5):\n",
    "    run_iterator(t_d_init_op,next_element,epoch_10)\n",
    "    run_iterator(v_d_init_op,next_element,epoch_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可馈送迭代器\n",
    "- 用`tf.dadta.Iterator.from_string_handle`方法创建迭代器\n",
    "- 可以和`tf.placeholder`一起使用，通过`feed_dict`机制，来选择所使用的`Iterator`\n",
    "- 功能与__可重新初始化迭代器__相同\n",
    "- 在迭代器之间切换，不需要从数据集的开头，初始化迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先创建多个Dataset对象\n",
    "t_dataset=tf.data.Dataset.range(epoch_10).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()\n",
    "v_dadtaset=tf.data.Dataset.range(epoch_5)\n",
    "\n",
    "# 创建handle\n",
    "handle=tf.placeholder(tf.string,shape=[])\n",
    "\n",
    "# 创建可馈送迭代器\n",
    "iterator=tf.data.Iterator.from_string_handle(handle,t_dataset.output_types,t_dataset.output_shapes)\n",
    "# 获取迭代元素\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# 可提供迭代器与各种不同的迭代器一同使用\n",
    "t_iterator=t_dataset.make_one_shot_iterator()\n",
    "v_iterator=v_dadtaset.make_initializable_iterator()\n",
    "\n",
    "# 返回可评估的tensor\n",
    "t_handle=sess.run(t_iterator.string_handle())\n",
    "v_handle=sess.run(v_iterator.string_handle())\n",
    "\n",
    "\n",
    "while True:\n",
    "    for _ in range(epoch_10):\n",
    "        sess.run(next_element,feed_dict={handle:t_handle})\n",
    "    \n",
    "    sess.run(v_iterator.initializer)\n",
    "    for _ in range(epoch_5):\n",
    "        sess.run(next_element,feed_dict={handle:v_handle})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 消耗迭代器中的值\n",
    "调用 `Iterator.get_next()` 并不会立即使迭代器进入下个状态。必须在 TensorFlow 表达式中使用此函数返回的 `tf.Tensor` 对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "iterator = dataset.make_initializer_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "result = tf.add(next_element,next_element)\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "       print(sess.run(result))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"End of dataset\") \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果数据集的每个元素都具有相同的嵌套结构.\n",
    "\n",
    "`next1`、`next2` 和 `next3` 是由同一个操作/节点（通过 `Iterator.get_next()` 创建）生成的张量\n",
    "\n",
    "因此，评估其中任何一个张量都全使所有组件进入下个状态\n",
    "\n",
    "迭代器消耗会在一个表达式中包含所有组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset3.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存迭代器状态\n",
    "- `tf.contrib.data.make_saveable_from_iterator`函数通过迭代器创建一个`SaveableObject`，该对象可用于保存和恢复迭代器的当前状态\n",
    "- __可保存对象__可以添加到 tf.train.Saver 变量列表或`tf.GraphKeys.SAVEABLE_OBJECTS`集合中\n",
    "- 用与`tf.Variable` 相同的方式进行保存和恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个可保存迭代器的对象\n",
    "saveable = tf.contrib.data.make_saveable_from_iterator(iterator)\n",
    "\n",
    "# 通过将迭代器状态添加到可保存对象集合来保存它.\n",
    "tf.add_to_collection(tf.GraphKeys.SAVEABLE_OBJECTS, saveable)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "  if should_checkpoint:\n",
    "    saver.save(path_to_checkpoint)\n",
    "\n",
    "# 恢复迭代器状态\n",
    "with tf.Session() as sess:\n",
    "  saver.restore(sess, path_to_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 消耗NumPy数组\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
