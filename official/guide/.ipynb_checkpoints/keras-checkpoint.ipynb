{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建简单的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列模型\n",
    "最常见模型类型是层的堆叠`tf.keras.Sequential`模型，构建简单的全连接网络（即多层感知器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "mode=keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置层\n",
    "使用`tf.keras.layers`方法创建层，重要参数：\n",
    "- `activation`：设置层的激活函数\n",
    "- `kernel_initizlizer`和`bias_initializer`：创建层权重的初始化方案\n",
    "- `kernel_regularizer`和`bias_regularizer`：应用层权重的正则化方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置层\n",
    "mode.add(keras.layers.Dense(64,activation='relu'))\n",
    "mode.add(keras.layers.Dense(64,activation='relu'))\n",
    "mode.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compile`方法配置模型的__学习流程__，三个重要参数\n",
    "- `optimizer`:此对象指定训练过程\n",
    "- `loss`:在优化期间最小化的函数\n",
    "- `metrics`:用于监控训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置模型的学习流程\n",
    "# 方式一：\n",
    "mode.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# # 方法二：\n",
    "# mode.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "#              loss=tf.keras.losses.categorical_crossentropy,\n",
    "#              metrics=[tf.keras.metrics.categorical_crossentropy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data():\n",
    "    data = np.random.random((1000,32))\n",
    "    labels=np.random.random((1000,10))\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "`fit`方法的三个重要参数：\n",
    "- `epochs`:以周期为单位进行训练\n",
    "- `batch_size`:当传递np数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次\n",
    "- `validation_data`:对模型进行原型设计时，需要轻松监控该模型在某些验证数据上达到的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 11.5228 - acc: 0.1020\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 11.4995 - acc: 0.0950\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 11.4917 - acc: 0.1360\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 99us/step - loss: 11.4855 - acc: 0.1310\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 11.4829 - acc: 0.1310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 11.4758 - acc: 0.1510\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 11.4721 - acc: 0.1660\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 11.4688 - acc: 0.1520\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 101us/step - loss: 11.4647 - acc: 0.1610\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 11.4606 - acc: 0.1710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207148600b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取np数据\n",
    "data,labels=random_data()\n",
    "# 训练模型，使模型与训练数据拟合\n",
    "mode.fit(data,labels,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据并进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 180us/step - loss: 11.4587 - acc: 0.0920 - val_loss: 11.5233 - val_acc: 0.0910\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 145us/step - loss: 11.4442 - acc: 0.0980 - val_loss: 11.5235 - val_acc: 0.0980\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 145us/step - loss: 11.4379 - acc: 0.1150 - val_loss: 11.5248 - val_acc: 0.1060\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 11.4314 - acc: 0.1280 - val_loss: 11.5239 - val_acc: 0.1010\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 11.4273 - acc: 0.1360 - val_loss: 11.5237 - val_acc: 0.1040\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 158us/step - loss: 11.4222 - acc: 0.1420 - val_loss: 11.5273 - val_acc: 0.1040\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 144us/step - loss: 11.4192 - acc: 0.1400 - val_loss: 11.5261 - val_acc: 0.0980\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 142us/step - loss: 11.4141 - acc: 0.1470 - val_loss: 11.5274 - val_acc: 0.1090\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 143us/step - loss: 11.4116 - acc: 0.1510 - val_loss: 11.5314 - val_acc: 0.0960\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 142us/step - loss: 11.4079 - acc: 0.1480 - val_loss: 11.5330 - val_acc: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207378708d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels=random_data()\n",
    "vdata,vlabels=random_data()\n",
    "\n",
    "mode.fit(data,labels,epochs=10,batch_size=32,validation_data=(vdata,vlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用dataset数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset=dataset.batch(32)\n",
    "dataset=dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit`方法使用`steps_per_epoch`参数(表示模型在进入下一个周期之前运行的训练步数)。由于`Dataset`会生成批次数据，因此该代码段不需要`batch_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 11.4007 - acc: 0.1573\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4058 - acc: 0.1573\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3801 - acc: 0.1531\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3779 - acc: 0.1708\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3618 - acc: 0.1708\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3888 - acc: 0.1823\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3549 - acc: 0.1906\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3696 - acc: 0.1906\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3755 - acc: 0.1844\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3671 - acc: 0.2062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20737887c18>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode.fit(dataset,epochs=10,steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用dataset数据与验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset=dataset.batch(32).repeat()\n",
    "\n",
    "vdataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "vdataset=vdataset.batch(32).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据并进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 11.3637 - acc: 0.1969 - val_loss: 11.3147 - val_acc: 0.2604\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.3625 - acc: 0.2000 - val_loss: 11.7880 - val_acc: 0.1979\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3378 - acc: 0.2031 - val_loss: 11.0630 - val_acc: 0.1667\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3358 - acc: 0.2010 - val_loss: 11.0452 - val_acc: 0.2396\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.3195 - acc: 0.2073 - val_loss: 11.3801 - val_acc: 0.1979\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.3470 - acc: 0.1990 - val_loss: 11.1372 - val_acc: 0.2708\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3128 - acc: 0.2125 - val_loss: 11.5357 - val_acc: 0.1979\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.3268 - acc: 0.2146 - val_loss: 11.4099 - val_acc: 0.2083\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3326 - acc: 0.2104 - val_loss: 11.4358 - val_acc: 0.1979\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.3243 - acc: 0.2229 - val_loss: 11.3126 - val_acc: 0.2083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20737b46978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode.fit(dataset,epochs=10,steps_per_epoch=30,validation_data=vdataset,validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估所提供数据的推理模式损失和指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 77us/step\n",
      "30/30 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.324138259887695, 0.2125]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels=random_data()\n",
    "# np数据评估\n",
    "mode.evaluate(data,labels,batch_size=32)\n",
    "# 数据集评估\n",
    "mode.evaluate(dataset,steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在提供数据的推理中预测最后一层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "data,_=random_data()\n",
    "result=mode.predict(data,batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09435935, 0.10380907, 0.1081499 , 0.10928555, 0.11181375,\n",
       "        0.09394258, 0.09118545, 0.10411217, 0.09785696, 0.08548521],\n",
       "       [0.10236298, 0.10276906, 0.10694765, 0.10114335, 0.1043352 ,\n",
       "        0.04990427, 0.10238858, 0.1277579 , 0.11241903, 0.08997203],\n",
       "       [0.09669232, 0.09915235, 0.11148491, 0.10231792, 0.09097207,\n",
       "        0.07128315, 0.11085076, 0.1178905 , 0.10544659, 0.09390943]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建高级模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数式API\n",
    "`tf.kerasa.Sequential`模型是层的简单堆叠，无法表示任意模型\n",
    "\n",
    "用__Keras函数式API__可以构建复杂的模型拓扑，例如：\n",
    "- 多输入模型\n",
    "- 多输出模型\n",
    "- 具有共享层模型（同一层被调用多次）\n",
    "- 具有非序列数据流的模型（例如，剩余连接）\n",
    "\n",
    "使用函数式API构建的模型具有以下特征：\n",
    "- 层实例可调用并返回张量\n",
    "- 输入张量和输出张量用于定义`tf.keras.Model`实例\n",
    "- 此模型的训练方式和`Sequential`模型一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用函数式API构建简单的全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.Input(shape=(32,))\n",
    "\n",
    "# 层实例调用并返回张量\n",
    "x=keras.layers.Dense(64,activation='relu')(inputs)\n",
    "x=keras.layers.Dense(64,activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在给定输入和输出的情况下实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 299us/step - loss: 11.5289 - acc: 0.0980\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 95us/step - loss: 11.4910 - acc: 0.0920\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 11.4619 - acc: 0.1060\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 98us/step - loss: 11.4535 - acc: 0.1150\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 96us/step - loss: 11.4460 - acc: 0.1380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2072a12d3c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型子类化\n",
    "通过`tf.keras.Model`进行子类化定义自己的__前向传播__来构建自定义的模型\n",
    "- 在`__init__`方法中创建层\n",
    "- 在`call`方法中定义前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义前身传播进行子类化的`tf.keras.Model`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self,num_class=10):\n",
    "        super(MyModel,self).__init__(name='my_model')\n",
    "        self.num_class=num_class\n",
    "        self.dense_1=keras.layers.Dense(32,activation='relu')\n",
    "        self.dense_2=keras.layers.Dense(num_class,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        '''定义前向传播'''\n",
    "        x=self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        '''使用子类化的模型，则需要覆盖此函数'''\n",
    "        shape=tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1]=self.num_class\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化新模型类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 255us/step - loss: 11.4819 - acc: 0.1110\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 97us/step - loss: 11.4524 - acc: 0.1050\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 11.4415 - acc: 0.1060\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 109us/step - loss: 11.4359 - acc: 0.1160\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 103us/step - loss: 11.4308 - acc: 0.1220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20737b6c390>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建自定义的模型\n",
    "model = MyModel(10)\n",
    "\n",
    "# 配置模型的学习流程\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.1),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_crossentropy])\n",
    "\n",
    "# 拟合数据\n",
    "mode.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义层\n",
    "通过`tf.keras.layers.Layer`进行子类化并实现以下方法来创建自定义层：\n",
    "- `build`：创建层的权重\n",
    "- `call`：定义前向传播\n",
    "- `computer_output_shape`：指定在给定输入形状的情况下如何计算层的输出形状\n",
    "- 可以通过实现`get_config`方法和`from_config`类方法序列化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用核矩阵实现输入`matmul`的自定义层示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        self.output_dim=output_dim\n",
    "        super(MyLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        shape=tf.TensorShape((input_shape[1],self.output_dim))\n",
    "        \n",
    "#         为这一层创建一个可训练的权重变量\n",
    "        self.kernel=self.add_weight(name='kernel',shape=shape,initializer='uniform',trainable=True)\n",
    "        \n",
    "#         最后一定要调用这个\n",
    "        super(MyLayer,self).build(input_shape)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.kernel)\n",
    "    \n",
    "    def complete_output_shape(self,input_shape):\n",
    "        shape=tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1]=self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config=super(MyLayer,self).get_config()\n",
    "        base_config['output_dim']=self.output_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls,config):\n",
    "        return cls(**config)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义层创建模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 13.1539 - categorical_accuracy: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 12.4717 - categorical_accuracy: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 12.0226 - categorical_accuracy: 0.0920\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 11.8999 - categorical_accuracy: 0.0900\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 11.8653 - categorical_accuracy: 0.0910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207378864e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建序列模型\n",
    "model=tf.keras.Sequential([MyLayer(10),keras.layers.Activation('softmax')])\n",
    "\n",
    "# 配置模型的学习流程\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss=keras.losses.categorical_crossentropy,\n",
    "             metrics=[keras.metrics.categorical_accuracy])\n",
    "# 拟合数据\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调\n",
    "回调是传递给模型的__对象__，用于在训练期间自定义该模型并扩展其行为\n",
    "- `tf.keras.callbacks.ModelCheckpoint`：定期保存模型的检查点\n",
    "- `tf.keras.callbacks.LearningRateScheduler`：动态更改学习速率\n",
    "- `tf.keras.callbacks.EarlyStoppint`：在验证效果不再改进时中断训练\n",
    "- `tf.keras.callbacks.TensorBoard`：监控模型的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 163us/step - loss: 11.8379 - categorical_accuracy: 0.0890 - val_loss: 11.8985 - val_categorical_accuracy: 0.0990\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 11.8125 - categorical_accuracy: 0.0890 - val_loss: 11.8726 - val_categorical_accuracy: 0.0950\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 127us/step - loss: 11.7873 - categorical_accuracy: 0.0900 - val_loss: 11.8485 - val_categorical_accuracy: 0.0960\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 11.7639 - categorical_accuracy: 0.0910 - val_loss: 11.8306 - val_categorical_accuracy: 0.0920\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 127us/step - loss: 11.7421 - categorical_accuracy: 0.0890 - val_loss: 11.8079 - val_categorical_accuracy: 0.0910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207406e8588>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(vdata, vlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅保存权重\n",
    "使用`tf.keras.Model.save_weights`保存并加载模型的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查点文件格式保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5格式保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅保存配置\n",
    "可保存模型的配置，对模型架构进行序列化\n",
    "\n",
    "即使没有定义原始模型的代码，该配置也可以重新创建并初始化相同的模型\n",
    "\n",
    "__子类化模型不可序列化，因为它们的架构由`call`方法中的Python代码定义__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json格式序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str=model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 格式化json_str\n",
    "pprint.pprint(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model=tf.keras.models.model_from_json(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML格式序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_str=model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model=tf.keras.models.model_from_yaml(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存整个模型\n",
    "将整个模型保存到一个文件中，包括__权重值、模型配置、优化器配置__\n",
    "\n",
    "便可以设置检查点并稍后从完全相同的状态继续训练，无需访问原始代码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
