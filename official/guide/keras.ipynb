{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建简单的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列模型\n",
    "最常见模型类型是层的堆叠`tf.keras.Sequential`模型，构建简单的全连接网络（即多层感知器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "mode=keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置层\n",
    "使用`tf.keras.layers`方法创建层，重要参数：\n",
    "- `activation`：设置层的激活函数\n",
    "- `kernel_initizlizer`和`bias_initializer`：创建层权重的初始化方案\n",
    "- `kernel_regularizer`和`bias_regularizer`：应用层权重的正则化方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置层\n",
    "mode.add(keras.layers.Dense(64,activation='relu'))\n",
    "mode.add(keras.layers.Dense(64,activation='relu'))\n",
    "mode.add(keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compile`方法配置模型的__学习流程__，三个重要参数\n",
    "- `optimizer`:此对象指定训练过程\n",
    "- `loss`:在优化期间最小化的函数\n",
    "- `metrics`:用于监控训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置模型的学习流程\n",
    "# 方式一：\n",
    "mode.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "# # 方法二：\n",
    "# mode.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "#              loss=tf.keras.losses.categorical_crossentropy,\n",
    "#              metrics=[tf.keras.metrics.categorical_crossentropy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data():\n",
    "    data = np.random.random((1000,32))\n",
    "    labels=np.random.random((1000,10))\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "`fit`方法的三个重要参数：\n",
    "- `epochs`:以周期为单位进行训练\n",
    "- `batch_size`:当传递np数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次\n",
    "- `validation_data`:对模型进行原型设计时，需要轻松监控该模型在某些验证数据上达到的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 313us/step - loss: 11.5382 - acc: 0.1100\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.4855 - acc: 0.1190\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.4778 - acc: 0.1190\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.4726 - acc: 0.1290\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.4682 - acc: 0.1310\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.4643 - acc: 0.1260\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.4595 - acc: 0.1320\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.4558 - acc: 0.1260\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 11.4512 - acc: 0.1500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 11.4482 - acc: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26736850160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取np数据\n",
    "data,labels=random_data()\n",
    "# 训练模型，使模型与训练数据拟合\n",
    "mode.fit(data,labels,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据并进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 11.5522 - acc: 0.0790 - val_loss: 11.4582 - val_acc: 0.0960\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.5370 - acc: 0.1130 - val_loss: 11.4560 - val_acc: 0.0970\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.5316 - acc: 0.1280 - val_loss: 11.4563 - val_acc: 0.0850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5257 - acc: 0.1200 - val_loss: 11.4580 - val_acc: 0.0990\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5214 - acc: 0.1290 - val_loss: 11.4587 - val_acc: 0.0880\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 11.5178 - acc: 0.1390 - val_loss: 11.4618 - val_acc: 0.0960\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 11.5132 - acc: 0.1470 - val_loss: 11.4600 - val_acc: 0.0970\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.5090 - acc: 0.1490 - val_loss: 11.4616 - val_acc: 0.0980\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 11.5046 - acc: 0.1690 - val_loss: 11.4636 - val_acc: 0.1010\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.4999 - acc: 0.1640 - val_loss: 11.4653 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674c0839b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels=random_data()\n",
    "vdata,vlabels=random_data()\n",
    "\n",
    "mode.fit(data,labels,epochs=10,batch_size=32,validation_data=(vdata,vlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用dataset数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset=dataset.batch(32)\n",
    "dataset=dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit`方法使用`steps_per_epoch`参数(表示模型在进入下一个周期之前运行的训练步数)。由于`Dataset`会生成批次数据，因此该代码段不需要`batch_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 11.4995 - acc: 0.1604\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 931us/step - loss: 11.5377 - acc: 0.1594\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 964us/step - loss: 11.5063 - acc: 0.1677\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5286 - acc: 0.1625\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 964us/step - loss: 11.5099 - acc: 0.1646\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 931us/step - loss: 11.4999 - acc: 0.1573\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 831us/step - loss: 11.5390 - acc: 0.1740\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 798us/step - loss: 11.4952 - acc: 0.1771\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - ETA: 0s - loss: 11.6524 - acc: 0.18 - 0s 931us/step - loss: 11.5156 - acc: 0.1719\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 831us/step - loss: 11.5058 - acc: 0.1823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674c099cf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode.fit(dataset,epochs=10,steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用dataset数据与验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "dataset=dataset.batch(32).repeat()\n",
    "\n",
    "vdataset=tf.data.Dataset.from_tensor_slices((data,labels))\n",
    "vdataset=vdataset.batch(32).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拟合数据并进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 11.4581 - acc: 0.1948 - val_loss: 11.3925 - val_acc: 0.1562\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 698us/step - loss: 11.4940 - acc: 0.1969 - val_loss: 11.6574 - val_acc: 0.2396\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 931us/step - loss: 11.4604 - acc: 0.1958 - val_loss: 11.4830 - val_acc: 0.1771\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 863us/step - loss: 11.4838 - acc: 0.1917 - val_loss: 11.1180 - val_acc: 0.2500\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 831us/step - loss: 11.4639 - acc: 0.2052 - val_loss: 11.0720 - val_acc: 0.2083\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 731us/step - loss: 11.4536 - acc: 0.2031 - val_loss: 11.7156 - val_acc: 0.1771\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 865us/step - loss: 11.4932 - acc: 0.1958 - val_loss: 11.2724 - val_acc: 0.2604\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 698us/step - loss: 11.4488 - acc: 0.2188 - val_loss: 11.6071 - val_acc: 0.1458\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 831us/step - loss: 11.4693 - acc: 0.2031 - val_loss: 11.7245 - val_acc: 0.2917\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 792us/step - loss: 11.4583 - acc: 0.2083 - val_loss: 11.2753 - val_acc: 0.2083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674c0bfcc0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode.fit(dataset,epochs=10,steps_per_epoch=30,validation_data=vdataset,validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估所提供数据的推理模式损失和指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 29us/step\n",
      "30/30 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.40997527440389, 0.23333333333333334]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,labels=random_data()\n",
    "# np数据评估\n",
    "mode.evaluate(data,labels,batch_size=32)\n",
    "# 数据集评估\n",
    "mode.evaluate(dataset,steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在提供数据的推理中预测最后一层的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "data,_=random_data()\n",
    "result=mode.predict(data,batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10691622, 0.09844066, 0.09566999, 0.07328409, 0.14637627,\n",
       "        0.0934908 , 0.12641561, 0.0985145 , 0.08315478, 0.0777372 ],\n",
       "       [0.0827874 , 0.06978317, 0.09850818, 0.10871132, 0.12982221,\n",
       "        0.1014108 , 0.0881303 , 0.13951005, 0.09126016, 0.09007637],\n",
       "       [0.08995933, 0.10691826, 0.10005227, 0.10218644, 0.09650246,\n",
       "        0.11524831, 0.09682024, 0.10151553, 0.10202208, 0.08877509]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建高级模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数式API\n",
    "`tf.kerasa.Sequential`模型是层的简单堆叠，无法表示任意模型\n",
    "\n",
    "用__Keras函数式API__可以构建复杂的模型拓扑，例如：\n",
    "- 多输入模型\n",
    "- 多输出模型\n",
    "- 具有共享层模型（同一层被调用多次）\n",
    "- 具有非序列数据流的模型（例如，剩余连接）\n",
    "\n",
    "使用函数式API构建的模型具有以下特征：\n",
    "- 层实例可调用并返回张量\n",
    "- 输入张量和输出张量用于定义`tf.keras.Model`实例\n",
    "- 此模型的训练方式和`Sequential`模型一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用函数式API构建简单的全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.Input(shape=(32,))\n",
    "\n",
    "# 层实例调用并返回张量\n",
    "x=keras.layers.Dense(64,activation='relu')(inputs)\n",
    "x=keras.layers.Dense(64,activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在给定输入和输出的情况下实例化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 175us/step - loss: 11.6860 - acc: 0.1070\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.6295 - acc: 0.1120\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 11.6059 - acc: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.5868 - acc: 0.1100\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 11.5743 - acc: 0.1160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674c04a5c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs,outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型子类化\n",
    "通过`tf.keras.Model`进行子类化定义自己的__前向传播__来构建自定义的模型\n",
    "- 在`__init__`方法中创建层\n",
    "- 在`call`方法中定义前向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义前身传播进行子类化的`tf.keras.Model`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self,num_class=10):\n",
    "        super(MyModel,self).__init__(name='my_model')\n",
    "        self.num_class=num_class\n",
    "        self.dense_1=keras.layers.Dense(32,activation='relu')\n",
    "        self.dense_2=keras.layers.Dense(num_class,activation='sigmoid')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        '''定义前向传播'''\n",
    "        x=self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        '''使用子类化的模型，则需要覆盖此函数'''\n",
    "        shape=tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1]=self.num_class\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化新模型类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 142us/step - loss: 11.6137 - acc: 0.0840\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 11.5772 - acc: 0.1030\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5675 - acc: 0.1210\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5620 - acc: 0.1130\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 11.5561 - acc: 0.1210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674c0f62e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建自定义的模型\n",
    "model = MyModel(10)\n",
    "\n",
    "# 配置模型的学习流程\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.1),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=[tf.keras.metrics.categorical_crossentropy])\n",
    "\n",
    "# 拟合数据\n",
    "mode.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义层\n",
    "通过`tf.keras.layers.Layer`进行子类化并实现以下方法来创建自定义层：\n",
    "- `build`：创建层的权重\n",
    "- `call`：定义前向传播\n",
    "- `computer_output_shape`：指定在给定输入形状的情况下如何计算层的输出形状\n",
    "- 可以通过实现`get_config`方法和`from_config`类方法序列化层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用核矩阵实现输入`matmul`的自定义层示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        self.output_dim=output_dim\n",
    "        super(MyLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        shape=tf.TensorShape((input_shape[1],self.output_dim))\n",
    "        \n",
    "#         为这一层创建一个可训练的权重变量\n",
    "        self.kernel=self.add_weight(name='kernel',shape=shape,initializer='uniform',trainable=True)\n",
    "        \n",
    "#         最后一定要调用这个\n",
    "        super(MyLayer,self).build(input_shape)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.kernel)\n",
    "    \n",
    "    def complete_output_shape(self,input_shape):\n",
    "        shape=tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1]=self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config=super(MyLayer,self).get_config()\n",
    "        base_config['output_dim']=self.output_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls,config):\n",
    "        return cls(**config)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义层创建模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 140us/step - loss: 12.6504 - categorical_accuracy: 0.1040\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 12.3413 - categorical_accuracy: 0.1090\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 12.1103 - categorical_accuracy: 0.1120\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 12.0407 - categorical_accuracy: 0.1140\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 12.0077 - categorical_accuracy: 0.1130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674bf33dd8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建序列模型\n",
    "model=tf.keras.Sequential([MyLayer(10),keras.layers.Activation('softmax')])\n",
    "\n",
    "# 配置模型的学习流程\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "             loss=keras.losses.categorical_crossentropy,\n",
    "             metrics=[keras.metrics.categorical_accuracy])\n",
    "# 拟合数据\n",
    "model.fit(data,labels,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回调\n",
    "回调是传递给模型的__对象__，用于在训练期间自定义该模型并扩展其行为\n",
    "- `tf.keras.callbacks.ModelCheckpoint`：定期保存模型的检查点\n",
    "- `tf.keras.callbacks.LearningRateScheduler`：动态更改学习速率\n",
    "- `tf.keras.callbacks.EarlyStoppint`：在验证效果不再改进时中断训练\n",
    "- `tf.keras.callbacks.TensorBoard`：监控模型的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 62us/step - loss: 11.9804 - categorical_accuracy: 0.1140 - val_loss: 11.8559 - val_categorical_accuracy: 0.1080\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 11.9524 - categorical_accuracy: 0.1080 - val_loss: 11.8290 - val_categorical_accuracy: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 11.9264 - categorical_accuracy: 0.1110 - val_loss: 11.8060 - val_categorical_accuracy: 0.1040\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 11.9020 - categorical_accuracy: 0.1190 - val_loss: 11.7838 - val_categorical_accuracy: 0.1040\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 11.8778 - categorical_accuracy: 0.1170 - val_loss: 11.7632 - val_categorical_accuracy: 0.1070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2674bfc8080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "  # Interrupt training if `val_loss` stops improving for over 2 epochs\n",
    "  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "  # Write TensorBoard logs to `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks,\n",
    "          validation_data=(vdata, vlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存和恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅保存权重\n",
    "使用`tf.keras.Model.save_weights`保存并加载模型的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查点文件格式保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x2674e768a58>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5格式保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仅保存配置\n",
    "可保存模型的配置，对模型架构进行序列化\n",
    "\n",
    "即使没有定义原始模型的代码，该配置也可以重新创建并初始化相同的模型\n",
    "\n",
    "__子类化模型不可序列化，因为它们的架构由`call`方法中的Python代码定义__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json格式序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str=model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend': 'tensorflow',\n",
      " 'class_name': 'Sequential',\n",
      " 'config': [{'class_name': 'MyLayer',\n",
      "             'config': {'batch_input_shape': [None, 32],\n",
      "                        'dtype': 'float32',\n",
      "                        'name': 'my_layer',\n",
      "                        'output_dim': 10,\n",
      "                        'trainable': True}},\n",
      "            {'class_name': 'Activation',\n",
      "             'config': {'activation': 'softmax',\n",
      "                        'dtype': 'float32',\n",
      "                        'name': 'activation',\n",
      "                        'trainable': True}}],\n",
      " 'keras_version': '2.1.6-tf'}\n"
     ]
    }
   ],
   "source": [
    "# 格式化json_str\n",
    "pprint.pprint(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: MyLayer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-015474306cb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfresh_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[1;34m(json_string, custom_objects)\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    171\u001b[0m             custom_objects=dict(\n\u001b[0;32m    172\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 list(custom_objects.items())))\n\u001b[0m\u001b[0;32m    174\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m       \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[1;32md:\\program files\\python367\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    161\u001b[0m       \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'from_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m       \u001b[0marg_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown layer: MyLayer"
     ]
    }
   ],
   "source": [
    "fresh_model=tf.keras.models.model_from_json(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML格式序列化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_str=model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_model=tf.keras.models.model_from_yaml(yaml_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存整个模型\n",
    "将整个模型保存到一个文件中，包括__权重值、模型配置、优化器配置__\n",
    "\n",
    "便可以设置检查点并稍后从完全相同的状态继续训练，无需访问原始代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.load_model('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
